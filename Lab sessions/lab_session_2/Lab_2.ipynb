{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEN1221 Statistical Analysis of Choice Behaviour \n",
    "\n",
    "## `Session Lab 02:`\n",
    "## `The Mixed Logit model`\n",
    "\n",
    "**Delft University of Technology**<br>\n",
    "**Q2 2023**<br>\n",
    "**Instructor:** Sander van Cranenburgh<br>\n",
    "**TA:**  Gabriel Nova <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Instructions`\n",
    "\n",
    "**Lab sessions aim to:**<br>\n",
    "* Illustrate how models and theory discussed in the classroom work out in practice.\n",
    "* Help you gather hands-on modelling and data analysis skills.\n",
    "\n",
    "\n",
    "**Lab sessions are:**<br>\n",
    "* Learning environments where you work with Python and get support from TA and fellow students.\n",
    "* Not graded and do not have to be submitted.\n",
    "* A good preparation for the graded partial exam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Use of AI tools`\n",
    "AI tools, such as ChatGPT and Co-pilot, are great tools to assist with programming. Moreover, in your later careers, you will work in a world where such tools are widely available. As such, we **encourage** you to use AI tools **effectively**. However, be careful not to overestimate the capacity of AI tools! AI tools cannot replace you: you still have to conceptualise the problem, dissect it and structure it to conduct proper analysis. We recommend being especially **reticent** with using AI tools for the more conceptual and reflection-oriented questions. <br>\n",
    "Futhermore **be aware** that during the `partial exam`, you will not have access to these tools (since internet access will be restricted)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Workspace set-up`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 1: Local environment**<br>\n",
    "Uncomment the following cell if you are running this notebook on your local environment to install all dependencies on your Python version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 2: Google Colab**<br>\n",
    "Uncomment the following cell if you are running this notebook on Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/SEN1221TUD/Q2_2023\n",
    "#!mv \"/content/Q2_2023/Lab sessions/lab_session_2/data\" /content/data\n",
    "#!mv \"/content/Q2_2023/Lab sessions/lab_session_2/biogeme.toml\" /content\n",
    "\n",
    "#!pip install biogeme\n",
    "#import os\n",
    "#os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Application: Estimating the Value of Travel Time`\n",
    "\n",
    "In this lab session, we will investigate the \"Value of Travel Time\" (VTT) distribution. The VTT of a traveller reflects the amount of money the traveller is **willing to pay** to reduce their travel time. The VTT is used to determine the benefits of new infrastructure projects. As travel time savings are the dominant and most salient benefits of new infrastructure, accurate inference of the distribution of the VTT is crucial for a rigorous underpinning of policy decisions. <br>\n",
    "\n",
    "During this lab, we will apply Mixed Logit choice models. We aim to uncover how tastes for travel time and travel cost are distributed in the population. Most of the analyses in this lab session are carried out in the so-called willingness-to-pay space. Willingness-to-pay space facilitates the inference of the VTT distribution.<br>\n",
    "\n",
    "For this study, we will use Stated Choice (SC) data (`Norway_VTT_2009.csv`) collected in 2009 to compute the Norwegian VTT. In this SC experiment, respondents faced nine choice tasks involving two alternatives and two attributes (travel cost and travel time). The data set consists of 5,832 participants, resulting in a total of 52,488 choice observations. The figure below shows one of the choice tasks (note that for the purposes of illustration we converted the currency unit (Kronor) into euros).\n",
    "\n",
    "![SC](data/sc_experiment.png)\n",
    "\n",
    "**`Learning objectives lab session 02`**\n",
    "\n",
    "After completing the following exercises, you will be able to:\n",
    "* Estimate Mixed Logit models that capture taste heterogeneity and panel effects\n",
    "* Interpret the modelling outcomes of Mixed Logit models\n",
    "* Specify utility models in Willingness-to-pay space\n",
    "* Discuss the impact of the number of draws on the modelling outcomes\n",
    "\n",
    "\n",
    "\n",
    "**`This lab consists of 5 parts and has 3 exercises`**\n",
    "\n",
    "**Part 1**: Load and explore the data set\n",
    "\n",
    "**Part 2**: Linear-additive RUM-MNL model\n",
    "\n",
    "**Part 3**: Mixed Logit model for capturing taste heterogeneity \n",
    "\n",
    "**Part 4**: Willingness-to-Pay space \n",
    "- Exercise 1: \"ML with log-normally distributed VTT\"\n",
    "\n",
    "**Part 5**: Panel Mixed Logit model\n",
    "\n",
    "- Exercise 2: \"Panel ML model with log-normally distributed VTT\"\n",
    "\n",
    "- Exercise 3: \"Impact of the number of draws\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Import packages`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, we will import all the libraries that we will use in this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biogeme\n",
    "import biogeme.logging as blog\n",
    "import biogeme.database as db\n",
    "import biogeme.biogeme as bio\n",
    "from biogeme import models\n",
    "from biogeme.expressions import Beta, Variable, bioDraws, log, MonteCarlo, exp, bioMultSum, exp\n",
    "\n",
    "# General packages\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from pathlib import Path\n",
    "import toml\n",
    "import time\n",
    "from scipy.stats import norm, lognorm\n",
    "\n",
    "# Pandas setting to show all columns when displaying a pandas dataframe\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `1. Load and explore the data set` <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the data set\n",
    "data_path = Path('data/Norway_VTT_2009.csv')\n",
    "df = pd.read_table(data_path, sep=',')\n",
    "\n",
    "# Show descriptive statistics\n",
    "round(df.describe(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data set contains the following variables:<br>\n",
    "\n",
    "| Variable       | Description                                                  | Type    |\n",
    "|---------------|-------------------------------------------------------------|---------|\n",
    "| `RespID`        | Unique identifier for each survey response             | Integer |\n",
    "| `CostL`         | Travel cost of left alternative [min]                  | Decimal |\n",
    "| `CostR`         | Travel cost of right alternative [min]                 | Decimal |\n",
    "| `TimeL`         | Travel time of left alternative [eur]                  | Decimal |\n",
    "| `TimeR`         | Travel time of right alternative [eur]                 | Decimal |\n",
    "| `Chosen`        | Indicates the alternative chosen       | Categorical |\n",
    "| `Mode`          | Type of Transport mode               | Categorical    |\n",
    "| `Gender`        | Gender of the respondent                                     | Categorical    |\n",
    "| `AgeClass`      | Classification of the respondent's age                       | Categorical    |\n",
    "| `IncClass`      | Classification of the respondent's income                    | Categorical    |\n",
    "| `Purpose`       | Purpose of the trip                                     | Integer    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we take the following data preprocessing steps:\n",
    "\n",
    "1. We keep only observations for the purpose 'long distance commute' and travel model 'car'.\n",
    "\n",
    "2. We convert the unit of cost from Norwegian Krone to euros to ease interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Keep only entries purpose == 5 (Long distance trips) & Mode == 1 (Car)\n",
    "df = df.loc[(df['Purpose'] == 5) & (df['Mode'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Convert the monetary unit to euros\n",
    "NOK2euro_exchange_rate = 9\n",
    "df[['CostL','CostR']] = df[['CostL','CostR']] .div(NOK2euro_exchange_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `2. Linear-additive RUM-MNL model`<br>\n",
    "We first estimate a linear-aditive RUM-MNL model. This model serves as our **benchmark** to compare against. But, before we can do this, we need to create the Biogeme database object and specify the optimiser and logger settings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Biogeme database`<br>\n",
    "To estimate a model in Biogeme, we must create the data set as a Biogeme database object and the attributes as Biogeme variable objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Biogeme database object\n",
    "biodata = db.Database('Norway2009VTT', df)\n",
    "\n",
    "# Create Biogeme variable objects\n",
    "CostL  = Variable('CostL')\n",
    "CostR  = Variable('CostR')\n",
    "TimeL  = Variable('TimeL')\n",
    "TimeR  = Variable('TimeR')\n",
    "Chosen = Variable('Chosen')\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Biogeme optimiser and logging settings`<br>\n",
    "The file `biogeme.toml` contains the settings for the optimiser. In this file, we set the number of draws for estimating Mixed Logit models to 50. We use a relatively low number to avoid long estimation times.<br>\n",
    "Also, we invoke a so-called `logger` which enables us to see the progress during estimation.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the number of draws in the .toml file. \n",
    "with open('biogeme.toml', 'r') as file:\n",
    "    tomldata = toml.load(file)\n",
    "\n",
    "# Modify the number of draws\n",
    "tomldata['MonteCarlo']['number_of_draws'] = 50\n",
    "\n",
    "# Write the modified data back to the .toml file\n",
    "with open('biogeme.toml', 'w') as file:\n",
    "    toml.dump(tomldata, file)\n",
    "\n",
    "# Create a logger to monitor the estimation progress\n",
    "# if logger does not exist create it, else use it\n",
    "try:\n",
    "    logger\n",
    "except NameError:    \n",
    "    logger = blog.get_screen_logger(level=blog.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Create a linear-additive RUM-MNL model`<br>\n",
    "Now, we have the biogeme database object and set the environment, we can estimate our first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the model a name\n",
    "model_name = 'Benchmark MNL VTT model'\n",
    "\n",
    "# Define model parameters\n",
    "B_tt = Beta('B_tt', -0.1, None, None, 0)\n",
    "B_tc = Beta('B_tc', -0.1, None, None, 0)\n",
    "\n",
    "# Definition of the utility functions\n",
    "VL = B_tt * TimeL + B_tc * CostL\n",
    "VR = B_tt * TimeR + B_tc * CostR\n",
    "\n",
    "# Associate utility functions with alternatives\n",
    "V = {1: VL, 2: VR}     \n",
    "\n",
    "# Associate the availability conditions with the alternatives\n",
    "av = {1: 1, 2: 1} \n",
    "\n",
    "# Compute probability of the chosen alternative\n",
    "prob = models.logit(V, av, Chosen)\n",
    "\n",
    "# Take the log of the probability\n",
    "logprob = log(prob)\n",
    "\n",
    "# Create the Biogeme estimation object containing the data and the model\n",
    "biogeme = bio.BIOGEME(biodata, logprob)\n",
    "\n",
    "# Set reporting levels\n",
    "biogeme.generate_pickle = False\n",
    "biogeme.generate_html = False\n",
    "biogeme.saveIterations = False\n",
    "biogeme.modelName = model_name\n",
    "\n",
    "# Compute the null loglikelihood for reporting\n",
    "biogeme.calculateNullLoglikelihood(av)\n",
    "\n",
    "# Estimate the model and print the results\n",
    "results = biogeme.estimate()\n",
    "print(results.short_summary())\n",
    "\n",
    "# Get the results in a pandas table\n",
    "beta_hat = results.getEstimatedParameters()\n",
    "print(beta_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Compute the Value of Travel Time`<br><br>\n",
    "The linear-additive RUM-MNL model allows for easy computation of the (mean) VTT. <br>\n",
    "\n",
    "$VTT = {\\frac{dV}{dtt}}/{\\frac{dV}{dtc}}$<br><br>\n",
    "$VTT = \\frac{\\beta_{tt}}{\\beta_{tc}}$\n",
    "\n",
    "To take the ratio, we access the estimated betas in the `beta_hat` dataframe that was created in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the value of travel time and print the mean VTT\n",
    "# We multiply by 60 to convert the value of travel time from minutes to hours\n",
    "VTT_MNL = 60*(beta_hat.loc['B_tt']['Value']/beta_hat.loc['B_tc']['Value'])\n",
    "print(f'Value of travel time MNL model:  ‚Ç¨{VTT_MNL:.2f} per hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `3. Mixed Logit model for capturing taste heterogeneity`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.1 Theory`<br>\n",
    "In the MNL model, we postulate that tastes (e.g., ùõΩ_tc) are equal across people in the population. As such, the taste parameter of an MNL model represents the mean taste in the population. The Mixed Logit (ML) model resolves this limitation. It explicitly models taste heterogeneity by means of random variables.\n",
    "\n",
    "Mathematically, the unconditional choice probability is given by:\n",
    "\n",
    "$P_{ni} = \\int_{\\beta_n}    [P_{ni}|\\beta_n] \\cdot f(\\beta_n|\\sigma)d\\beta_n$\n",
    "\n",
    "As can be seen, the ML choice probability does not have a closed-form expression. Therefore, it needs to be approximated using simulation.<br>\n",
    "To do that, we simulate the choice probabilities using a large number of draws `(R)` from the density function $f(Œ≤_n|\\sigma)$. <br>\n",
    "That is, we compute the conditional choice probability (which is a simple MNL) for each draw of $\\beta_n^{r}$ with $r=1,..,R$, and then take the average across the draws to compute the unconditional choice probability.\n",
    "\n",
    "<span style=\"text-decoration: overline;\">P</span>$_{ni} = \\frac{1}{R} \\sum_{r=1}^R P_{ni}(Œ≤_n^r)$\n",
    "\n",
    "Finally, we use the unconditional choice probabilities to compute the Log-Likelihood of the data given the model:\n",
    "\n",
    "$LL(X,|\\beta,\\sigma)= \\sum_{n=1}^N \\sum_{j=1}^J y_{nj} \\cdot ln($<span style=\"text-decoration: overline;\">P</span>$_{nj})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.2 ML with normally distributed taste parameters`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To estimate an ML, model with normally distributed taste parameters, we must specify the random parameters (for all randomly distributed betas that we wish to estimate). To do this in Biogeme, we use the following code to construct the random parameter for $\\beta_{tt}$:<br>\n",
    "\n",
    "                B_tt_rnd = B_tt + sigma_tt * bioDraws('B_tt_rnd', 'NORMAL_HALTON2')\n",
    "\n",
    "Note that apart from the random parameter for B_tt_rnd, the utility function is the same as under our linear-additive RUM-MNL benchmark model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Model specification` <br>\n",
    "\n",
    "Now, we will define random and nonrandom parameters, the utility functions, and their availabilities. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model parameters\n",
    "B_tt = Beta('b_tt', -0.1, None, None, 0)\n",
    "B_tc = Beta('b_tc', -0.1, None, None, 0)    \n",
    "sigma_tt = Beta('sigma_tt', 1, None, None, 0)\n",
    "\n",
    "# Construct the random taste parameter for beta_tt\n",
    "B_tt_rnd = B_tt + sigma_tt * bioDraws('B_tt_rnd', 'NORMAL_HALTON2')\n",
    "\n",
    "# Definition of the utility functions \n",
    "V_L = B_tt_rnd * TimeL + B_tc * CostL\n",
    "V_R = B_tt_rnd * TimeR + B_tc * CostR   \n",
    "\n",
    "# Create a dictionary to list the utility functions with the numbering of alternatives\n",
    "V = {1: V_L, 2: V_R}\n",
    "            \n",
    " # Create a dictionary to describe the availability conditions of each alternative\n",
    "av = {1: 1, 2: 1} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Estimation through simulation` \n",
    "\n",
    "We use the Monte Carlo simulation to estimate the random parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the model a name\n",
    "model_name = 'ML with normal distributed B_tt'\n",
    "\n",
    "# The conditional probability of the chosen alternative is a logit\n",
    "condProb = models.logit(V, av ,Chosen)\n",
    "\n",
    "# The unconditional probability is obtained by simulation\n",
    "uncondProb = MonteCarlo(condProb)\n",
    "\n",
    "# The Log-likelihood is the log of the unconditional probability\n",
    "LL = log(uncondProb)\n",
    "\n",
    "# Create the Biogeme estimation object containing the data and the model\n",
    "biogeme = bio.BIOGEME(biodata , LL)\n",
    "\n",
    "# Set reporting levels\n",
    "biogeme.generate_pickle = False\n",
    "biogeme.generate_html = False\n",
    "biogeme.saveIterations = False\n",
    "biogeme.modelName = model_name\n",
    "\n",
    "# Compute the null loglikelihood for reporting\n",
    "biogeme.calculateNullLoglikelihood(av)\n",
    "\n",
    "# Estimate the parameters\n",
    "results = biogeme.estimate()\n",
    "print(results.short_summary())\n",
    "\n",
    "# Get the results in a pandas table\n",
    "beta_hat = results.getEstimatedParameters()\n",
    "print(beta_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean value of travel time\n",
    "VTT_ML = 60*(beta_hat.loc['b_tt']['Value']/beta_hat.loc['b_tc']['Value'])\n",
    "print(f'Value of travel time ML model:  ‚Ç¨{VTT_ML:.2f} per hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.3 Reflection`<br>\n",
    "We do not also estimate $\\beta_{tc}$ as a random parameter for two reasons.<br>\n",
    "1. Jointly estimating $\\beta_{tc-rnd}$ and $\\beta_{tt-rnd}$ is tedious because of collinearity\n",
    "2. When we compute the VTT we divide by $\\beta_{tc}$. In case $\\beta_{tc}$ would be **normally** distributed, we would divide by zero for some of the mass of the distribution. Dividing by zero leads to infinite VTT values. Hence, a normally distributed $\\beta_{tc}$ is generally not a good idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `4. Willingness-to-Pay space`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.1. Theory`<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People are differently sensitive to cost. But, as discussed under 3.3, we cannot specify $\\beta_{tc}$ as a randomly distributed parameter (or, to be more precise, not as one that uses a distribution which has support over the full domain, like a normal distribution). To circumvent this problem, we can cleverly re-parameterise our model. This reparametrisation involves a transformation from **`utility space`** to **`Willingness-to-Pay (WTP) space`**. This transformation allows us to estimate the VTT (distribution) directly, and simplifies the modelling. It works as follows:<br><br>\n",
    "\n",
    "\n",
    "The utility specification in `utility space` is:\n",
    "\n",
    "$V_1 = \\beta_{tc} \\cdot TC_1 + \\beta_{tt} \\cdot TT_1$<br>\n",
    "$V_2 = \\beta_{tc} \\cdot TC_2 + \\beta_{tt} \\cdot TT_2$<br><br>\n",
    "\n",
    "We factorise $\\beta_{tc}$ in both utility functions. This gives us:\n",
    "\n",
    "$V_1 = \\beta_{tc} \\cdot (TC_1 + (\\frac{\\beta_{tt}}{\\beta_{tc}}) \\cdot TT_1)$<br>\n",
    "$V_2 = \\beta_{tc} \\cdot (TC_2 + (\\frac{\\beta_{tt}}{\\beta_{tc}}) \\cdot TT_2)$<br><br>\n",
    "\n",
    "Noting that $VTT = \\frac{\\beta_{tt}}{\\beta_{tc}}$, we obtain:\n",
    "\n",
    "$V_1 = \\beta_{tc} \\cdot (TC_1 + VTT \\cdot TT_1)$<br>\n",
    "$V_2 = \\beta_{tc} \\cdot (TC_2 + VTT \\cdot TT_2)$<br><br>\n",
    "\n",
    "Hence, with this model, we can directly estimate the VTT (and $\\beta_{tc}$). Therefore, this model is in the `Willingness-to-Pay space`. Let's see how this works out for a simple MNL model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the model a name\n",
    "model_name = 'Benchmark MNL in WTP space'\n",
    "\n",
    "# Define model parameters\n",
    "vtt  = Beta('vtt',     1, None, None, 0)\n",
    "B_tc = Beta('B_tc', -0.1, None, None, 0)\n",
    "\n",
    "# Definition of the utility functions\n",
    "VL = B_tc * (CostL + vtt * TimeL)\n",
    "VR = B_tc * (CostR + vtt * TimeR)\n",
    "\n",
    "# Associate utility functions with alternatives\n",
    "V = {1: VL, 2: VR}     \n",
    "\n",
    "# Associate the availability conditions with the alternatives\n",
    "av = {1: 1, 2: 1} \n",
    "\n",
    "# Compute probability of the chosen alternative\n",
    "prob = models.logit(V, av, Chosen)\n",
    "\n",
    "# Take the log of the probability\n",
    "logprob = log(prob)\n",
    "\n",
    "# Create the Biogeme estimation object containing the data and the model\n",
    "biogeme = bio.BIOGEME(biodata, logprob)\n",
    "\n",
    "# Set reporting levels\n",
    "biogeme.generate_pickle = False\n",
    "biogeme.generate_html = False\n",
    "biogeme.saveIterations = False\n",
    "biogeme.modelName = model_name\n",
    "\n",
    "# Compute the null loglikelihood for reporting\n",
    "biogeme.calculateNullLoglikelihood(av)\n",
    "\n",
    "# Estimate the parameters and print the results\n",
    "results = biogeme.estimate()\n",
    "print(results.short_summary())\n",
    "\n",
    "# Get the results in a pandas table\n",
    "beta_hat = results.getEstimatedParameters()\n",
    "print(beta_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the value of travel time\n",
    "VTT_WTP_MNL = 60 * beta_hat.loc['vtt']['Value']\n",
    "print(f'Value of travel time MNL model in WTP space:  ‚Ç¨{VTT_WTP_MNL:.2f} per hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.2 Reflection`<br>\n",
    "Comparing these results with the benchmark MNL VTT model, we make two observations:\n",
    "* We obtain `EXACTLY` the same VTT\n",
    "* We obtain `EXACTLY` the same model fit \n",
    "* **We immediately obtain the VTT and the associated standard error!** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.3. ML in Willingness-to-Pay space`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ML with normally distributed taste parameters`<br>\n",
    "Now, let's see how WTP space enables us to directly estimate the VTT distribution in the context of the Mixed Logit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the model a name\n",
    "model_name = 'ML WTP space with normally distributed vtt'\n",
    "\n",
    "# Parameters definition enabling the construction of random parameters\n",
    "vtt = Beta('vtt',    0.1, None, None, 0)\n",
    "B_tc = Beta('b_tc', -0.1, None, None, 0)    \n",
    "sigma_vtt = Beta('sigma_vtt', 1, None, None, 0)\n",
    "\n",
    "# Construction of random parameters   \n",
    "vtt_rnd = vtt + sigma_vtt * bioDraws('vtt_rnd', 'NORMAL_HALTON2')\n",
    "\n",
    "# Definition of the utility functions \n",
    "V_L = B_tc * (CostL + vtt_rnd * TimeL)\n",
    "V_R = B_tc * (CostR + vtt_rnd * TimeR)   \n",
    "\n",
    "# Create a dictionary to list the utility functions with the numbering of alternatives\n",
    "V = {1: V_L, 2: V_R}\n",
    "            \n",
    " # Create a dictionary to describe the availability conditions of each alternative\n",
    "av = {1: 1, 2: 1} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The conditional probability of the chosen alternative is a logit\n",
    "condProb = models.logit(V, av ,Chosen)\n",
    "\n",
    "# The unconditional probability is obtained by simulation\n",
    "uncondProb = MonteCarlo(condProb)\n",
    "\n",
    "# The Log-likelihood is the log of the unconditional probability\n",
    "LL = log(uncondProb)\n",
    "\n",
    "# Create the Biogeme estimation object containing the data and the model\n",
    "biogeme = bio.BIOGEME(biodata , LL)\n",
    "\n",
    "# Set reporting levels\n",
    "biogeme.generate_pickle = False\n",
    "biogeme.generate_html = False\n",
    "biogeme.saveIterations = False\n",
    "biogeme.modelName = model_name\n",
    "\n",
    "\n",
    "# Compute the null loglikelihood for reporting\n",
    "biogeme.calculateNullLoglikelihood(av)\n",
    "\n",
    "# Estimate the parameters and print the results\n",
    "results = biogeme.estimate()\n",
    "print(results.short_summary())\n",
    "\n",
    "# Get the results in a pandas table\n",
    "beta_hat = results.getEstimatedParameters()\n",
    "print(beta_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the value of travel time\n",
    "VTT_WTP_ML = 60*beta_hat.loc['vtt']['Value']\n",
    "print(f'Value of travel time ML model in WTP space:  ‚Ç¨{VTT_WTP_ML:.2f} per hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Visualisation of the estimated VTT distribution`<br>\n",
    "Visualisation of the estimated distribution helps to get a feeling for the shape of the distribution that we aim to recover. To do so, we use the estimated values for the mean (vtt) and standard deviation (sigma_vtt). <br>\n",
    "Note that the visualisation distinguishes between values in the positive and negative domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the estimated normal distribution\n",
    "\n",
    "# Get the mean and standard deviation from the beta_hat table\n",
    "mean_normal = beta_hat.loc['vtt']['Value']\n",
    "std_dev_normal = beta_hat.loc['sigma_vtt']['Value']\n",
    "\n",
    "# Create a vector of 100 points between +/- 4 standard deviations from the mean\n",
    "x= np.linspace(mean_normal - 4*std_dev_normal, mean_normal + 4*std_dev_normal, 100)\n",
    "\n",
    "# Plot the normal distribution in the positive domain. \n",
    "# Note that the x-axis is rescaled by 60 to convert from minutes to hours\n",
    "# The scipy function \"norm.pdf(x,mean, std_dev)\" computes the probability density function of the normal distribution\n",
    "plt.plot(x[x>0]*60, norm.pdf(x[x>0], mean_normal, std_dev_normal))\n",
    "\n",
    "# Plot the normal distribution in the negative domain. \n",
    "plt.plot(x[x<0]*60, norm.pdf(x[x<0], mean_normal, std_dev_normal), color='red',linestyle='dashed')\n",
    "\n",
    "# Add a vertical line to highlight the zero\n",
    "plt.plot([0,0], [0,np.max(norm.pdf(x[x>0], mean_normal, std_dev_normal))], color='black',linestyle='dashed')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('VTT [euro/hour]')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.ylim([0,1])\n",
    "plt.title(f'Distribution of the VTT')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.4 Reflection`<br>\n",
    "* Using a Mixed Logit model in the Willingness-to-Pay space, we are able to estimate the distribution of the VTT **directly** . Hence, this model allows jointly for unobserved heterogeneity in cost and time without running into problems caused by dividing by zero.  \n",
    "* But, we see that a substantial part of the VTT distribution lies in the negative domain. This is behaviourally counterintuitive. In general, people prefer to arrive quicker at their destination rather than later. This is due to the assumption that the VTT is normally distributed. Perhaps this assumption needs revisiting...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Exercise 1: ML with log-normally distributed VTT`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, **you** will try the assumption that the VTT distribution in the population is **`log-normally distributed`** (as opposed to normally distributed).<br>\n",
    "\n",
    "To do that, you must create a random vtt parameter with a log-normal VTT distribution. Draws from the log-normal distribution can be obtained from draws from the normal distribution as follows: <br>\n",
    "\n",
    "            vtt_rnd = exp(mu + sigma  * bioDraws('vtt_rnd', 'NORMAL_HALTON2'))\n",
    "            \n",
    "\n",
    "Estimate this model and interpret its results.<br>\n",
    "\n",
    "`Questions:`\n",
    "\n",
    "`A` Compare the log-likelihood of the ML model with normal distribution and with log-normal distribution. Which model fits better?<br>\n",
    "\n",
    "`B` What can you conclude from the `vtt` and `sigma` parameters?<br>\n",
    "\n",
    "`C` Compute the mean of the estimated log-normal distribution, i.e. `mean_lognormal` (based on your estimated `mu` and `sigma`). <br>\n",
    "\n",
    "**Hint**, take a look at [https://en.wikipedia.org/wiki/Log-normal_distribution](https://en.wikipedia.org/wiki/Log-normal_distribution) to see how this is done. Look for the formula for the mean in the right-hand side panel on the web page.\n",
    "\n",
    "`D` Plot the shape of the log-normal distribution for the estimated mu and sigma. <br>\n",
    "\n",
    " **Hint**, you can use the  scipy function \"lognorm\". But lognorm is differently parameterised. That is, instead of using a location parameter `mu`, it requires a `scale` parameter. The scale is simply the exponent of the location parameter mu (i.e. scale = exp(mu)). <br>\n",
    "    \n",
    "Alternatively, you compute it directly from the formula yourself using the location `mu` and standard deviation $\\sigma$:<br>\n",
    "    ${\\frac {1}{x\\sigma {\\sqrt {2\\pi }}}}\\ \\exp \\left(-{\\frac {\\left(\\ln x-\\mu \\right)^{2}}{2\\sigma ^{2}}}\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `5. Panel Mixed Logit model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus far, we have worked on the assumption that each choice observation is uncorrelated with all other choice observations. However, this data set contains multiple choices per respondent. In the ML modelling framework, we can also account for correlation in unobserved utility **across observations** of the same individual if we specify it as a panel ML model. In the panel ML model, the likelihood of the sequence of choices *t* = 1..*T* of an individual *n* is given by:  \n",
    "\n",
    "$L_n(i_1,...,i_{T})(\\beta_n|\\sigma) = \\int_{\\beta_n}\\Pi_{t=1}^T     P_{n}(i_t|\\beta_n) f(\\beta_n|\\sigma)d\\beta_n$\n",
    "\n",
    "This likelihood does not have a closed-form expression. Therefore, as before, it needs to be approximated using simulation. Let's re-estimate the ML model assuming a normally distributed VTT distribution while accounting for panel structure. To do this, we first need to convert the data set into a so-called wide data format. In a wide format data set, each row contains all the choices belonging to an individual. Conveniently, Biogeme has a built-in function to do this (but, rather inconveniently, the names of the columns still need to be renamed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `5.1. Preparing a wide Biogeme database for estimating panel ML model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell we transform our data set into a wide format, and create a new Biogeme database object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell Biogeme which variable is the identifier of the individuals\n",
    "biodata.panel('RespID')\n",
    "\n",
    "# Calculate the number of observations per individual\n",
    "obs_per_ind = biodata.data['RespID'].value_counts().unique()[0]\n",
    "print(f'Number of observations per individual: {obs_per_ind}')\n",
    "\n",
    "# Use biogeme's \"generateFlatPanelDataFrame to create a wide database in which each row corresponds to one individual\n",
    "df_wide = biodata.generateFlatPanelDataframe(identical_columns=None)\n",
    "\n",
    "# Rename the columns, such that they run from columnname_{0} to columnname_{n} \n",
    "renumbered_columns = {col: f'{col.split(\"_\")[1]}_{int(col.split(\"_\")[0])-1}' if len(col.split(\"_\")) == 2 else col for col in df_wide.columns}\n",
    "\n",
    "# Rename the columns using the dictionary\n",
    "df_wide.rename(columns=renumbered_columns, inplace=True)\n",
    "\n",
    "# Create Biogeme database object\n",
    "biodata_wide = db.Database('Norway2009VTT_wide', df_wide)\n",
    "biodata_wide.data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `5.2. Panel ML model with normally distributed VTT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the model a name\n",
    "model_name = 'Panel ML WTP space with normally distributed vtt'\n",
    "\n",
    "# Parameters definition enabling the construction of random parameters\n",
    "vtt       = Beta('vtt',       0.4, None, None, 0)\n",
    "B_tc      = Beta('b_tc',     -0.4, None, None, 0)    \n",
    "sigma_vtt = Beta('sigma_vtt ',  2, None, None, 0)\n",
    "\n",
    "# Construction of random parameters   \n",
    "vtt_rnd = vtt + sigma_vtt * bioDraws('vtt_rnd', 'NORMAL_HALTON2')\n",
    "\n",
    "# Definition of the utility functions\n",
    "# Note that we use list comprehension to create a list of utility functions for all observations of an individual \n",
    "V_L = [B_tc * (Variable(f'CostL_{q}') + vtt_rnd * Variable(f'TimeL_{q}')) for q in range(obs_per_ind)]\n",
    "V_R = [B_tc * (Variable(f'CostR_{q}') + vtt_rnd * Variable(f'TimeR_{q}')) for q in range(obs_per_ind)]\n",
    "\n",
    "# Create a dictionary to list the utility functions with the numbering of alternatives\n",
    "# Note that we use list comprehension to create a list of dictionaries\n",
    "V = [{1: V_L[q], 2: V_R[q]} for q in range(obs_per_ind)]\n",
    "           \n",
    "# Create a dictionary to describe the availability conditions of each alternative\n",
    "av = {1:1, 2:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The conditional probability of the chosen alternative is a logit\n",
    "condProb = [models.loglogit(V[q], av, Variable(f'Chosen_{q}')) for q in range(obs_per_ind)] \n",
    "\n",
    "# Take the product of the conditional probabilities\n",
    "condprobIndiv = exp(bioMultSum(condProb))   # exp to convert from logP to P again\n",
    "\n",
    "# The unconditional probability is obtained by simulation\n",
    "uncondProb = MonteCarlo(condprobIndiv)\n",
    "\n",
    "# The Log-likelihood is the log of the unconditional probability\n",
    "LL = log(uncondProb)\n",
    "\n",
    "# Create the Biogeme estimation object containing the data and the model\n",
    "biogeme = bio.BIOGEME(biodata_wide , LL)\n",
    "\n",
    "# Set reporting levels\n",
    "biogeme.generate_pickle = False\n",
    "biogeme.generate_html = False\n",
    "biogeme.saveIterations = False\n",
    "biogeme.modelName = model_name\n",
    "                                \n",
    "# Compute the null loglikelihood for reporting\n",
    "# Note that we need to compute it manually, as biogeme does not do this for panel data\n",
    "biogeme.nullLogLike = len(biodata_wide.data)*np.log(1/2)*obs_per_ind\n",
    "\n",
    "# Estimate the parameters and print the results\n",
    "results = biogeme.estimate()\n",
    "print(results.short_summary())\n",
    "\n",
    "# Get the results in a pandas table\n",
    "beta_hat = results.getEstimatedParameters()\n",
    "print(beta_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the value of travel time\n",
    "VTT_WTP_ML_PANEL_normal = 60 * beta_hat.loc['vtt']['Value']\n",
    "print(f'Value of travel time Panel ML model in WTP space:  ‚Ç¨{VTT_WTP_ML_PANEL_normal:.2f} per hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Exercise 2: Panel ML with log-normally distributed VTT`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, **you** will estimate a ML model under the assumption that the VTT is log-normally distributed, while accounting for panel effects.<br>\n",
    "\n",
    "To do so, copy the code from the Panel ML model in WTP space with normally distributed VTT, and create the log-normally distributed random parameter (as you have done in exercise 1).<br>  \n",
    "Estimate this model and interpret the results.<br>\n",
    "\n",
    "`Questions:`\n",
    "\n",
    "`A` Compare the log-likelihood of the ML models with the log-normally distributed VTTs, which do and do not account for the panel effect. Which model fits better?<br>\n",
    "\n",
    "`B` Compute the mean of the VTT for the Panel ML model with the log-normally distributed VTT and compare it with the non-panel model. Has it changed?<br>\n",
    "\n",
    "`C`  i. Print the recovered mean VTTs of the models we have estimated below each other.<br>\n",
    "* MNL model<br>\n",
    "* ML model with Normal distribution in utility space<br>\n",
    "* ML model with Normal distribution in wtp space<br>\n",
    "* ML model with Log-normal in wtp space<br>\n",
    "* Panel ML with Normal distribution in wtp space<br>\n",
    "* Panel ML with Log-normal distribution in wtp space<br>                     \n",
    "\n",
    "ii. Compare the VTTs of the models with a normal distribution and a log-normal distribution. Do you see a pattern? <br>\n",
    "\n",
    "iii. What could explain this pattern?<br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `5.4. Impact of the number of draws on modelling outcomes`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Exercise 3: Impact of the number of draws` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all the Mixed Logit models that we have estimated, we have used 50 draws (see the beginning of this notebook). We choose a relatively low number of draws to avoid long estimation times.  <br>\n",
    "\n",
    "Next, we analyse how sensitive the modelling outcomes are towards the number of draws. To do this, we have estimated a Panel Mixed Logit model using different numbers of draws, ranging from 33 to 2,000, and stored the results. <br>\n",
    "\n",
    "The following plots show the results. \n",
    "\n",
    "![Draws](data/draws_vs_.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Questions:`\n",
    "\n",
    "`A` The left-hand side plot shows that the VTT estimate gets more stable with an increasing number of draws. Can you explain why the estimate gets more stable? \n",
    "\n",
    "`B` What number of draws do you deem sufficient for estimating this model? Explain your answer.\n",
    "\n",
    "`C` The right-hand side plot shows a linear relation between the number of draws and the estimation time. Explain why a linear relation was to be expected.\n",
    "\n",
    "`D` Suppose we estimate a model with *K* random parameters. Would the relation between the number of draws and estimation time still be linear? Explain your answer. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`your anwsers here`<br>\n",
    "A. ... \n",
    "\n",
    "B. ....\n",
    "      \n",
    "C. ... \n",
    "        \n",
    "D. ...  \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is the code to create the plot \n",
    "\n",
    "# Create a dataframe to store the results\n",
    "df_out = pd.DataFrame(columns=['num_draws','VTT', 'LL','elapsed_time'])\n",
    "\n",
    "# Define the number of draws to be used for Monte-Carlo simulation\n",
    "num_draws = list(range(33, 201, 33))\n",
    "\n",
    "# Loop over the number of draws\n",
    "for R in num_draws:\n",
    "    \n",
    "    # Start the timer\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Give the model a name\n",
    "    model_name = f'Panel ML WTP space with log-normally distributed vtt with {R} draws'\n",
    "\n",
    "    # Change the number of draws in the .toml file\n",
    "    with open('biogeme.toml', 'r') as file:\n",
    "        data = toml.load(file)\n",
    "\n",
    "    # Modify the value\n",
    "    data['MonteCarlo']['number_of_draws'] = R\n",
    "\n",
    "    # Write the modified data back to the .toml file\n",
    "    with open('biogeme.toml', 'w') as file:\n",
    "        toml.dump(data, file)\n",
    "\n",
    "    # Parameters definition enabling the construction of random parameters\n",
    "    vtt         = Beta('vtt',       0.4, None, None, 0)\n",
    "    B_tc        = Beta('b_tc',     -0.4, None, None, 0)    \n",
    "    sigma_vtt   = Beta('sigma_vtt',   2, None, None, 0)\n",
    "\n",
    "    # Construction of random parameters   \n",
    "    vtt_rnd = exp(vtt + sigma_vtt * bioDraws('vtt_rnd', 'NORMAL_HALTON2'))\n",
    "\n",
    "    # Definition of the utility functions \n",
    "    V_L = [B_tc * (Variable(f'CostL_{q}') + vtt_rnd * Variable(f'TimeL_{q}')) for q in range(9)]\n",
    "    V_R = [B_tc * (Variable(f'CostR_{q}') + vtt_rnd * Variable(f'TimeR_{q}')) for q in range(9)]\n",
    "\n",
    "    # Create a dictionary to list the utility functions with the numbering of alternatives\n",
    "    V = [{1: V_L[q], 2: V_R[q]} for q in range(9)]\n",
    "            \n",
    "    # Create a dictionary to describe the availability conditions of each alternative\n",
    "    av = {1:1, 2:1}\n",
    "\n",
    "    # The conditional probability of the chosen alternative is a logit\n",
    "    condProb = [models.loglogit(V[q], av, Variable(f'Chosen_{q}')) for q in range(9)] \n",
    "\n",
    "    # Take the product of the conditional probabilities\n",
    "    condprobIndiv = exp(bioMultSum(condProb))   # exp to convert from logP to P again\n",
    "\n",
    "    # The unconditional probability is obtained by simulation\n",
    "    uncondProb = MonteCarlo(condprobIndiv)\n",
    "\n",
    "    # The Log-likelihood is the log of the unconditional probability\n",
    "    LL = log(uncondProb)\n",
    "\n",
    "    # Create the Biogeme estimation object containing the data and the model\n",
    "    biogeme = bio.BIOGEME(biodata_wide , LL)\n",
    "    \n",
    "    # Set reporting levels\n",
    "    biogeme.generate_pickle = False\n",
    "    biogeme.generate_html = False\n",
    "    biogeme.saveIterations = False\n",
    "    biogeme.modelName = model_name\n",
    "                                    \n",
    "    # Compute the null loglikelihood for reporting\n",
    "    biogeme.nullLogLike = len(biodata_wide.data)*np.log(1/2)*9\n",
    "\n",
    "    # Estimate the parameters\n",
    "    results = biogeme.estimate()\n",
    "    # print(results.short_summary())\n",
    "\n",
    "    # Get the results in a pandas table\n",
    "    beta_hat = results.getEstimatedParameters()\n",
    "    # print(beta_hat)\n",
    "\n",
    "    # End the timer\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f'Elapsed time: {elapsed_time:.2f} seconds\\n\\n')\n",
    "\n",
    "    # Compute the mean value of travel time\n",
    "    mu = beta_hat.loc['vtt']['Value']\n",
    "    sigma = beta_hat.loc['sigma_vtt']['Value'] \n",
    "    mean_lognormal_panel = np.exp(mu + np.square(sigma)/2) * 60\n",
    "    \n",
    "    # Add the results to the dataframe\n",
    "    df_R = pd.DataFrame({'num_draws': [R], 'VTT': [mean_lognormal_panel], 'LL': [results.getGeneralStatistics()['Final log likelihood'][0]], 'elapsed_time': [elapsed_time]})\n",
    "    df_out = pd.concat([df_out, df_R])\n",
    "\n",
    "# Show the results\n",
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results in a figure\n",
    "fig, ax = plt.subplots(1,3, figsize=(15,5), sharex=True)\n",
    "fig.tight_layout(w_pad=3)\n",
    "\n",
    "ax[0].plot(df_out['num_draws'], df_out['VTT'], marker='.')\n",
    "ax[0].set_xlabel('Number of draws')\n",
    "ax[0].set_ylabel('VTT [euro/hour]')\n",
    "ax[0].set_title('VTT')\n",
    "\n",
    "ax[1].plot(df_out['num_draws'], df_out['LL'], marker='.')\n",
    "ax[1].set_xlabel('Number of draws')\n",
    "ax[1].set_ylabel('Log-likelihood')\n",
    "ax[1].set_title('Log-likelihood')\n",
    "\n",
    "ax[2].plot(df_out['num_draws'], df_out['elapsed_time'], marker='.')\n",
    "ax[2].set_xlabel('Number of draws')\n",
    "ax[2].set_ylabel('Elapsed time [s]')\n",
    "ax[2].set_title('Elapsed time')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_biogeme",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
